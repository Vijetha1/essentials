import numpy as np
import random as rn
from scipy import io
import h5py
from scipy.misc import imresize as resize
import pdb
import json
import glob
import csv
from argparse import ArgumentParser
import numpy as np
from copy import deepcopy
from PIL import Image
import numpy as np
from itertools import cycle
import time
import cv2

np.random.seed(42)
rn.seed(12345)


def convertLevelDbtoHdf5(sourcePath, targetPath):
	"""
	Description:
		converts a level-db file (generated by caffe) to a hdf5 file.
	Args:
		sourcePath - file path at which the level-db file is present.
		targetPath - file path to which the hdf5 file is to be stored.
	Outputs:
		stores a hdf5file at the give path 'sourcePath'
	"""
	import caffe
	import leveldb
	from caffe.proto import caffe_pb2
	dbData = leveldb.LevelDB(sourcePath)
	datum = caffe_pb2.Datum()

	data = []
	for key, value in dbData.RangeIter():
	    datum.ParseFromString(value)
	    data.append(caffe.io.datum_to_array(datum))
	data = np.array(data)
	# pdb.set_trace()
	data = np.reshape(data, (data.shape[0], data.shape[1]))
	f = h5py.File(targetPath, 'w')
	f.create_dataset('data', data=data)
	f.close()


def mergeHdf5Files(listOfFilesToMerge, nameOfNewFile):
	fNew = h5py.File(nameOfNewFile, 'w')
	for i in range(len(listOfFilesToMerge)):
		fOld = h5py.File(listOfFilesToMerge[i][0], 'r')
		data = fOld['data'][:]
		fOld.close()
		fNew.create_dataset(listOfFilesToMerge[i][1], data=data)
		del data
	fNew.close()

def getRealValuedToCode(x, threshold):
	x = np.array(x>threshold, dtype='int32')
	return x

def oneHotVectors(x, n):
	if np.max(x) == 0:
		raise AssertionError()
	m = max(x.shape)
	y = np.zeros((m, n))
	x = np.reshape(x, (m, ))
	y[np.arange(m), x] = 1
	return y

def getWeightShapesFromModel(model, library='Keras'):
	weightShapes=[]
	print("Printing From Model")
	if library == 'Keras':
		nLayers = len(model.layers)
		for i in range(nLayers):
			nParamSets = len(model.layers[i].get_weights())
			assert nParamSets%2 == 0
			for j in range(int(nParamSets/2)):
				weightShapes.append([model.layers[i].get_weights()[2*j].shape, model.layers[i].get_weights()[2*j+1].shape])
				print(weightShapes[-1])
	return weightShapes


def getWeightShapesFromH5(fileName):
	f = h5py.File(fileName, 'r')
	allKeys=[k for k in f.keys()]
	weightShapes=[]
	print("Printing From saved weights")
	for layerNumber in range(len(allKeys)):
		subKeys = [k for k in f[allKeys[layerNumber]].keys()]
		assert len(subKeys)%2 == 0
		for i in range(int(len(subKeys)/2)):
			weightShapes.append([f[allKeys[layerNumber]][subKeys[2*i]][:].shape, f[allKeys[layerNumber]][subKeys[2*i+1]][:].shape])
			print(weightShapes[-1])
	f.close()
	return weightShapes

def getWeightShapesFromNpyFile(fileName):
	weights = np.load(fileName, encoding = 'bytes').item()
	weightKeys = [key for key in weights.keys() if '__' not in key]
	for i in range(len(weightKeys)):
		curDs = weights[weightKeys[i]]
		for j in range(len(curDs)):
			print(curDs[j].shape)

def convertThtoTf(srcFileName, dstFileName):
	from keras.utils.conv_utils import convert_kernel
	from shutil import copyfile
	copyfile(srcFileName, dstFileName)
	f = h5py.File(dstFileName, 'r+')
	allKeys=[k for k in f.keys()]
	for layerNumber in range(len(allKeys)):
		if 'conv' in allKeys[layerNumber]:
			subKeys = [k for k in f[allKeys[layerNumber]].keys()]
			for i in range(len(subKeys)):
				original_w = f[allKeys[layerNumber]][subKeys[i]][:]
				if i == 0:
					abcd = f[allKeys[layerNumber]][subKeys[0]]
					del f[allKeys[layerNumber]][subKeys[0]]
					pdb.set_trace()
					original_w = np.transpose(convert_kernel(original_w), (2, 3, 1, 0))
					data = f[allKeys[layerNumber]].create_dataset(subKeys[i], original_w.shape)
					data = original_w
	f.close()


def matToHdf5(srcFileName, dstFileName):
	data = io.loadmat(srcFileName)
	datasets = [key for key in data.keys() if '__' not in key]
	f = h5py.File(dstFileName, 'w')
	for i in range(len(datasets)):
		if datasets[i] == 'B_trn':
			f.create_dataset('train_hashes', data=data[datasets[i]])
		elif datasets[i] == 'B_tst':
			f.create_dataset('test_hashes', data=data[datasets[i]])
		elif datasets[i] == 'WtrueTestTraining':
			f.create_dataset('groundTruthSimilarity', data=data[datasets[i]])
		else:
			f.create_dataset(datasets[i], data=data[datasets[i]])
	f.close()

def prepImageData(images, chOrder='channelsLast', resizeHeight=256, resizeWidth=256, meanSubtractOrder='BGR', bsAxis = 0):
	images = batchSizeFirst(images, bsAxis)
	if chOrder == 'channelsLast':
		images = channelsFirstToLast(images)
	elif chOrder == 'channelsFirst':
		images = channelsLastToFirst(images)
	images = resizeImages(images, resizeHeight, resizeWidth)
	images = meanSubtract(images, meanSubtractOrder)
	return images

def im2Arr(path, chOrder='channelsLast', resizeHeight=256, resizeWidth=256, meanSubtractOrder='BGR'):
	import cv2
	try:
		image = cv2.imread(path)
		image = np.expand_dims(image, axis=0)
		image = prepImageData(image, chOrder='channelsLast', resizeHeight=256, resizeWidth=256, meanSubtractOrder='BGR')
		return image
	except:
		return None

def prepLabelData(labels, sourceType='uint', targetType='uint'):
	batchSize = max(labels.shape)
	if sourceType== 'uint' and targetType == 'uint':
		labels = np.reshape(labels, (batchSize, ))
	elif sourceType == 'oneHot' and targetType == 'uint':
		labels = np.array(np.argmax(labels, axis=-1), dtype='int32')
	else:
		raise NotImplementedError
	return labels

def makeCIFAR10(srcFileName, dstFileName, printInfo = True, 
				batchSize = 1000, 
				chOrder='channelsLast', 
				resizeHeight=256, 
				resizeWidth=256, 
				meanSubtractOrder='BGR', 
				labelSourceType='uint', 
				labelTargetType='uint'):
	fSrc = h5py.File(srcFileName, 'r')
	fDst = h5py.File(dstFileName, 'w')
	datasets = [key for key in fSrc.keys() if '__' not in key]
	for i in range(len(datasets)):
		dShape =  fSrc[datasets[i]][:].shape
		bs = np.max(dShape)
		bsOrder = np.argmax(dShape)
		print("Processing Dataset -"+str(datasets[i]))
		print("Total Samples - "+str(bs))
		if len(dShape) == 4 and np.max(fSrc[datasets[i]][:]) > 200:
			if chOrder == 'channelsFirst':
				fDst.create_dataset(datasets[i], (bs, 3, resizeHeight, resizeWidth))
			elif chOrder == 'channelsLast':
				fDst.create_dataset(datasets[i], (bs, resizeHeight, resizeWidth, 3))
			nBatches = int(bs/batchSize)
			for j in range(nBatches):
				if printInfo:
					print("# processed images - "+str(j*batchSize))
				if bsOrder == 3:
					image = fSrc[datasets[i]][:,:,:,j*batchSize:(j+1)*batchSize]
				elif bsOrder == 0:
					image = fSrc[datasets[i]][j*batchSize:(j+1)*batchSize,:,:,:]
				if len(image.shape) != 4:
					image = np.expand_dims(image, axis=bsOrder)
				data = prepImageData(image, chOrder, resizeHeight, resizeWidth, meanSubtractOrder, bsOrder)
				fDst[datasets[i]][j*batchSize:(j+1)*batchSize, ...] = data  # Assuming batch size always at the first dimension
		else:
			data = prepLabelData(fSrc[datasets[i]][:], labelSourceType, labelTargetType)
			fDst.create_dataset(datasets[i], data=data)
	fSrc.close()
	fDst.close()

def cleanH5(srcFile, dstFile, chOrder = 'channelsLast', batchSize=1000):
	pdb.set_trace()
	fSrc = h5py.File(srcFile, 'r')
	fDst = h5py.File(dstFile, 'w')
	datasets = [key for key in fSrc.keys() if '__' not in key]
	for i in range(len(datasets)):
		print("At dataset "+str(datasets[i]))
		ind = datasets[i].find('_')
		if 'img' in datasets[i]:
			newName = datasets[i][0:ind+1]+'data'
			bs = fSrc[datasets[i]][:].shape[0]
			fDst.create_dataset(newName, (bs, 256, 256, 3))
			for j in range(int(bs/batchSize)+1):
				if j%5 == 0:
					print("At "+str(j))
				data = fSrc[datasets[i]][j*batchSize:(j+1)*batchSize]
				data = np.transpose(data, (0, 2, 3, 1))
				fDst[newName][j*batchSize:(j+1)*batchSize, ...] = data
		elif 'label' in datasets[i]:
			newName = datasets[i][0:ind+1]+'labels'
			data = fSrc[datasets[i]][:]
			fDst.create_dataset(newName, data=data)
			del data
		elif 'vector' in datasets[i]:
			newName = datasets[i][0:ind+1]+'vectors'
			data = fSrc[datasets[i]][:]
			fDst.create_dataset(newName, data=data)
			del data
	fDst.close()
	fSrc.close()


def makeNUS(srcFileName, dstFileName, printInfo = True, 
				batchSize = 1000, 
				chOrder='channelsLast', 
				resizeHeight=256, 
				resizeWidth=256,
				meanSubtractOrder='BGR', 
				labelSourceType='uint', 
				labelTargetType='uint'):
	fSrc = h5py.File(srcFileName, 'r')
	fDst = h5py.File(dstFileName, 'w')
	datasets = [key for key in fSrc.keys() if '__' not in key]
	for i in range(len(datasets)):
		dShape =  fSrc[datasets[i]][:].shape
		bs = np.max(dShape)
		bsOrder = np.argmax(dShape)
		print("Processing Dataset -"+str(datasets[i]))
		print("Total Samples - "+str(bs))
		if len(dShape) == 4 and np.max(fSrc[datasets[i]][:]) > 200:
			if chOrder == 'channelsFirst':
				fDst.create_dataset(datasets[i], (bs, 3, resizeHeight, resizeWidth))
			elif chOrder == 'channelsLast':
				fDst.create_dataset(datasets[i], (bs, resizeHeight, resizeWidth, 3))
			nBatches = int(bs/batchSize)
			for j in range(nBatches):
				if printInfo:
					print("# processed images - "+str(j*batchSize))
				if bsOrder == 3:
					image = fSrc[datasets[i]][:,:,:,j*batchSize:(j+1)*batchSize]
				elif bsOrder == 0:
					image = fSrc[datasets[i]][j*batchSize:(j+1)*batchSize,:,:,:]
				if len(image.shape) != 4:
					image = np.expand_dims(image, axis=bsOrder)
				data = prepImageData(image, chOrder, resizeHeight, resizeWidth, meanSubtractOrder)
				fDst[datasets[i]][j*batchSize:(j+1)*batchSize, ...] = data  # Assuming batch size always at the first dimension
		else:
			data = prepLabelData(fSrc[datasets[i]][:], labelSourceType, labelTargetType)
			fDst.create_dataset(datasets[i], data=data)
	fSrc.close()
	fDst.close()
	
def getTagMatrix(excelFileName):
	raise NotImplementedError

def resizeImages(images, resizeHeight=256, resizeWidth = 256):
	order = images.shape
	ch = order.index(3)
	if ch == 1:
		images = channelsFirstToLast(images)
	resizedImages = np.zeros((images.shape[0], resizeHeight, resizeWidth, 3))
	for i in range(resizedImages.shape[0]):
		resizedImages[i,:,:,:] = resize(images[i], (resizeHeight, resizeWidth))
	if np.max(resizedImages) <= 1:
		resizedImages = 255.0*resizedImages
	if ch == 1:
		resizedImages = channelsLastToFirst(resizedImages)
	return resizedImages

def batchSizeFirst(images, bs=0):
	order = images.shape
	assert len(order) == 4
	if bs == 3:
		images = np.transpose(images, (3, 0, 1, 2))
	elif bs == 0:
		pass
	else:
		raise NotImplementedError
	return images

def cropImages(images, cropHeight=227, cropWidth=227):
	order = images.shape
	ch = order.index(3)
	if ch == 1:
		images = channelsFirstToLast(images)
	croppedImages = np.zeros((images.shape[0], cropHeight, cropWidth, 3))
	for i in range(croppedImages.shape[0]):
		randX = np.random.randint(images.shape[1]-cropHeight)
		randY = np.random.randint(images.shape[2]-cropWidth)
		croppedImages[i,:,:,:] = images[i,randX:randX+cropHeight,randY:randY+cropWidth,:]
	if ch == 1:
		croppedImages = channelsLastToFirst(croppedImages)
	return croppedImages

def channelsFirstToLast(images):
	order = images.shape
	ch = order.index(3)
	if ch == 1:
		images = np.transpose(images, (0, 2, 3, 1))
	return images

def channelsLastToFirst(images):
	order = images.shape
	ch = order.index(3)
	if ch == 3:
		images = np.transpose(images, (0, 3, 1, 2))
	return images

def meanSubtract(images, sourceDataSet='IMAGENET', order='RGB'):
	chOrder = images.shape
	ch = chOrder.index(3)	
	if ch == 1:
		images = channelsFirstToLast(images)
	if order == 'RGB':
		#in RGB order
	    images[:, :, :, 0] -= 123.68
	    images[:, :, :, 1] -= 116.779
	    images[:, :, :, 2] -= 103.939 # values copied from https://github.com/heuritech/convnets-keras/blob/master/convnetskeras/convnets.py
	elif order == 'BGR':
	    images[:, :, :, 0] -= 103.939
	    images[:, :, :, 1] -= 116.779
	    images[:, :, :, 2] -= 123.68 # values copied from https://github.com/heuritech/convnets-keras/blob/master/convnetskeras/convnets.py
	if ch == 1:
		images = channelsLastToFirst(images)
	return images


def shuffleInUnison(images, labels):
	perm = np.random.permutation(images.shape[0])
	images = images[perm]
	labels = labels[perm]
	return images, labels

def checkIfWeightsAreNotLost(model_1, model_2, layerList):
	for i in range(len(layerList)):
		sameWeights = False
		weights1 = model_1.layers[layerList[i]].get_weights()[0]
		weights2 = model_2.layers[layerList[i]].get_weights()[0]
		if weights1.shape != weights2.shape:
			print("Weights Shapes did not match")
			break
		else:
			totalNumberOfWeights = getTotalWeights(weights1.shape)
			if np.sum(weights1 == weights2) != totalNumberOfWeights:
				print("Weights are different")
				break
			else:
				sameWeights = True
	return sameWeights

def getTotalWeights(weightsShape):
	totalWeights = 1
	for i in range(len(weightsShape)):
		totalWeights = totalWeights*weightsShape[i]
	return totalWeights

def loadJsonFile(fileName):
	import json
	f = open(fileName, 'r')
	allData = json.load(f)
	f.close()
	return allData

def getTagVectorsForEachImage(data, imId=None, ind=None):
	if imId != None:
		ind = [i for i,x in enumerate(data) if x[0] == imId]
	elif ind != None:
		ind = ind
	else:
		ind = np.random.randint(len(data))
	vecs = data[ind][2]
	vecs = np.asarray(vecs)
	return vecs

def makeTrainTestSplits(imageIds, labels, labelType = 'oneHot', nImagesPerClassTrain=500, nImagesPerClassTest = 100):
	if labelType == 'oneHot':
		nClasses = labels.shape[1]
	nTrainImages = int(imageIds.shape[0]*0.7)
	trainImages = imageIds[0:nTrainImages]
	testImages = imageIds[nTrainImages:]
	trainLabels = labels[0:nTrainImages]
	testLabels = labels[nTrainImages:]

	trainSetImageIds = np.zeros((nClasses, nImagesPerClassTrain), dtype='uint32')
	trainSetLabels = np.zeros((nClasses, nImagesPerClassTrain, nClasses))
	for i in range(nClasses):
		consider = trainLabels[:, i] == 1
		curImageIds = trainImages[consider]
		curLabels = trainLabels[consider,:]
		curImageIds, curLabels = shuffleInUnison(curImageIds, curLabels)
		trainSetImageIds[i,:] = np.reshape(curImageIds[0:nImagesPerClassTrain], (nImagesPerClassTrain,))
		trainSetLabels[i, :, :] = curLabels[0:nImagesPerClassTrain]

	testSetImageIds = np.zeros((nClasses, nImagesPerClassTest), dtype='uint32')
	testSetLabels = np.zeros((nClasses, nImagesPerClassTest, nClasses))
	for i in range(nClasses):
		consider = testLabels[:, i] == 1
		curImageIds = testImages[consider]
		curLabels = testLabels[consider,:]
		curImageIds, curLabels = shuffleInUnison(curImageIds, curLabels)
		testSetImageIds[i,:] = np.reshape(curImageIds[0:nImagesPerClassTest], (nImagesPerClassTest,))
		testSetLabels[i, :, :] = curLabels[0:nImagesPerClassTest]
	
	trainSetImageIds = np.reshape(trainSetImageIds, (nClasses*nImagesPerClassTrain,))
	trainSetLabels = np.reshape(trainSetLabels, (nClasses*nImagesPerClassTrain, nClasses))
	testSetImageIds = np.reshape(testSetImageIds, (nClasses*nImagesPerClassTest,))
	testSetLabels = np.reshape(testSetLabels, (nClasses*nImagesPerClassTest,nClasses))
	return trainSetImageIds, trainSetLabels, testSetImageIds, testSetLabels

def removeOutliers(vecs, threshold):
	meanVector = np.zeros((300,))
	curVecs = np.asarray(vecs, dtype='float32')
	isNotZero = np.sum(curVecs == 0, axis = -1) != 300
	curVecs = curVecs[isNotZero]
	S = 1.0 - getCosineSimilarity(curVecs, batchSize=1, save=False, getFullMatrix=True)
	toConsider = np.sum(S < 0.0, axis=-1) != S.shape[0] -1 
	toConsider = curVecs[toConsider]
	if toConsider.shape[0] != 0:
		meanVector = np.mean(toConsider, axis=0)
	else:
		meanVector = np.mean(curVecs, axis=0)
	if np.sum(np.isnan(meanVector))!=0:
		pdb.set_trace()
	return meanVector

def readImageBatch(imagesPaths, folderName, resizeHeight=256, resizeWidth=256, cropHeight=227, cropWidth=227, sourceDataSet='IMAGENET', orderOfChannels='BGR'):
	'''
	Inputs:
	Outputs:
	'''
	imagesBatch = np.zeros((len(imagesPaths), 3, cropHeight, cropWidth))
	extracedImages = []
	counter = 0
	for i in range(len(imagesPaths)):
		try:
			image = readImage(folderName + imagesPaths[i])
			#pdb.set_trace()
			if np.sum(image != None):
				imagesBatch[counter,:,:,:] = image[0,:,:,:]
				counter = counter + 1
				extracedImages.append((i, imagesPaths[i]))
		except:
			pass
	imagesBatch = imagesBatch[0:counter,:,:,:]
	return imagesBatch, extracedImages
		
def getTriplets(nSamples, labels, batch_size):
	triplets = np.zeros((batch_size, 3), dtype='int32')
	ind = 0
	toFill = np.sum(np.sum(triplets, axis=-1)==0)
	while (toFill != 0):
		contextSamples = np.random.permutation(nSamples)
		contextSamples = contextSamples[0:batch_size]
		posSamples = np.random.permutation(nSamples)
		posSamples = posSamples[0:batch_size]
		negSamples = np.random.permutation(nSamples)
		negSamples = negSamples[0:batch_size]	
		L = labels[contextSamples]
		L_plus = labels[posSamples]
		L_minus = labels[negSamples]
		d_plus = np.reshape(np.sum(np.abs(L - L_plus), axis=1), (batch_size))
		d_minus = np.reshape(np.sum(np.abs(L - L_minus), axis=1), (batch_size))
		atleastOneCommonLabel_plus = np.sum(np.logical_and(L, L_plus), axis=1)
		atleastOneCommonLabel_minus = np.sum(np.logical_and(L, L_minus), axis=1)
		correct = np.logical_and(d_plus < d_minus, atleastOneCommonLabel_plus)
		reverse = np.logical_and(d_minus < d_plus, atleastOneCommonLabel_minus)
		nCorrect = np.sum(correct)
		nReverse = np.sum(reverse)
		triplets[ind:ind+nCorrect,0] = contextSamples[correct][0:toFill]
		triplets[ind:ind+nCorrect,1] = posSamples[correct][0:toFill]
		triplets[ind:ind+nCorrect,2] = negSamples[correct][0:toFill]
		ind = ind + nCorrect
		toFill = np.sum(np.sum(triplets, axis=-1)==0)
		triplets[ind:ind+nReverse,0] = contextSamples[reverse][0:toFill]
		triplets[ind:ind+nReverse,1] = negSamples[reverse][0:toFill]
		triplets[ind:ind+nReverse,2] = posSamples[reverse][0:toFill]
		ind = ind + nReverse
		toFill = np.sum(np.sum(triplets, axis=-1)==0)
	return triplets

def readImage(imageName, 
			libraryName='cv2', resizeHeight=256, resizeWidth=256, cropHeight=227, cropWidth=227, sourceDataSet='IMAGENET', orderOfChannels='BGR'):
	'''
    reads the image, resizes, crops and aligns channels with respect to the order inputted

    Inputs: 
        The path to the image

    Returns: 
        A 4 D numpy array of shape [Batch Size(which is 1 here), Channels, Image Height, Image Width]
    '''
	try:
	    image = cv2.imread(imageName)
	    image = np.transpose(image, (2, 0, 1))
	    image = np.expand_dims(image, axis=0)
	    image = resizeImages(image, resizeHeight, resizeWidth)
	    image = meanSubtract(image, sourceDataSet, orderOfChannels)
	    image = cropImages(image, cropHeight, cropWidth)
	except:
		print("skipped reading image")
		image = None
	return image
	

def getData(dataset='CIFAR10', channels_last=True):
	if dataset == 'CIFAR10':
		#This matrix is made by the MATLAB/MatConvNet/DPSH_IJCAI_ version 1.0_beta23 code. As per the code, the data should be in RGB format(verified visually) 
		data = sio.loadmat('./datasets/cifar-10.mat')

	trainData = data['train_data']
	trainLabels = data['train_L']
	queryData = data['test_data']
	queryLabels = data['test_L']
	galleryData = data['data_set']
	galleryLabels = data['dataset_L']
	if channels_last:
		trainData = np.transpose(trainData, (3, 0, 1, 2))
		queryData = np.transpose(queryData, (3, 0, 1, 2))
		galleryData = np.transpose(galleryData, (3, 0, 1, 2))
	else:
		raise NotImplementedError
	return trainData, trainLabels, queryData, queryLabels, galleryData, galleryLabels

def makeDataSet(imageIds, labels, labelType = 'oneHot', nImagesPerClassTrain=500, nImagesPerClassTest = 100):
	if labelType == 'oneHot':
		nClasses = labels.shape[1]
	nTrainImages = int(imageIds.shape[0]*0.7)
	trainImages = imageIds[0:nTrainImages]
	testImages = imageIds[nTrainImages:]
	trainLabels = labels[0:nTrainImages]
	testLabels = labels[nTrainImages:]

	trainSetImageIds = np.zeros((nClasses, nImagesPerClassTrain), dtype='uint32')
	trainSetLabels = np.zeros((nClasses, nImagesPerClassTrain, nClasses))
	for i in range(nClasses):
		consider = trainLabels[:, i] == 1
		curImageIds = trainImages[consider]
		curLabels = trainLabels[consider,:]
		curImageIds, curLabels = shuffleInUnison(curImageIds, curLabels)
		trainSetImageIds[i,:] = np.reshape(curImageIds[0:nImagesPerClassTrain], (nImagesPerClassTrain,))
		trainSetLabels[i, :, :] = curLabels[0:nImagesPerClassTrain]

	testSetImageIds = np.zeros((nClasses, nImagesPerClassTest), dtype='uint32')
	testSetLabels = np.zeros((nClasses, nImagesPerClassTest, nClasses))
	for i in range(nClasses):
		consider = testLabels[:, i] == 1
		curImageIds = testImages[consider]
		curLabels = testLabels[consider,:]
		curImageIds, curLabels = shuffleInUnison(curImageIds, curLabels)
		testSetImageIds[i,:] = np.reshape(curImageIds[0:nImagesPerClassTest], (nImagesPerClassTest,))
		testSetLabels[i, :, :] = curLabels[0:nImagesPerClassTest]
	
	trainSetImageIds = np.reshape(trainSetImageIds, (nClasses*nImagesPerClassTrain,))
	trainSetLabels = np.reshape(trainSetLabels, (nClasses*nImagesPerClassTrain, nClasses))
	testSetImageIds = np.reshape(testSetImageIds, (nClasses*nImagesPerClassTest,))
	testSetLabels = np.reshape(testSetLabels, (nClasses*nImagesPerClassTest,nClasses))
	return trainSetImageIds, trainSetLabels, testSetImageIds, testSetLabels

def generatePairs(images, labels, batch_size):
	n_classes = np.unique(labels).shape[0]
	images_classwise = np.zeros((n_classes, images.shape[0]/n_classes, images.shape[1], images.shape[2], images.shape[3]))
	for i in range(n_classes):
		curClass = labels == i
		images_classwise[i,:,:,:,:] = images[curClass,:,:,:]
	randomLabels = np.random.randint(10, size=batch_size)
	simLabels = randomLabels[0:batch_size/2]
	dissimLabels = randomLabels[batch_size/2:batch_size]
	imagePairs = []
	similarity = []
	queryLabs = []
	databaseLabs = []
	for i in range(len(simLabels)):
		randomImgNums = np.random.randint(images.shape[0]/n_classes, size=2)
		imagePairs.append([images_classwise[simLabels[i], randomImgNums[0], :, :, :], images_classwise[simLabels[i], randomImgNums[1], :, :, :]])
		similarity.append(1)
		queryLabs.append(simLabels[i])
		databaseLabs.append(simLabels[i])
	for i in range(len(dissimLabels)):
		randomImgNums = np.random.randint(images.shape[0]/n_classes, size=2)
		secondImageClass = dissimLabels[i]
		while(secondImageClass==dissimLabels[i]):
			secondImageClass = np.random.randint(n_classes)
		imagePairs.append([images_classwise[dissimLabels[i], randomImgNums[0], :, :, :], images_classwise[secondImageClass, randomImgNums[1], :, :, :]])
		similarity.append(0)
		queryLabs.append(dissimLabels[i])
		databaseLabs.append(secondImageClass)
	imagePairs = np.array(imagePairs)
	similarity = np.array(similarity)
	return imagePairs, similarity, np.asarray(queryLabs), np.asarray(databaseLabs)

def prepareData(dataset='CIFAR10'):
	trainData, trainLabels, queryData, queryLabels, galleryData, galleryLabels = getData(dataset=dataset)
	return trainData, trainLabels, queryData, queryLabels, galleryData, galleryLabels

def multiLabelGetVectors(data, dim=300, nClasses=81, nTags=1000, method='mean'):
	vecMat = np.zeros((len(data), dim))
	labels = np.zeros((len(data), nClasses))
	images = np.zeros((len(data), 1))
	tags = np.zeros((len(data), nTags))
	for i in range(len(data)):
		curRec = data[i]
		curVector = np.zeros((300, ))
		images[i] = curRec[0]
		labels[i] = curRec[1]
		if method == 'mean':
			for j in range(len(curRec[2])):
				curVector = curVector + curRec[2][j]
				tags[i][int(curRec[2][j][1])] = 1
			vecMat[i][:] = curVector/float(len(curRec[2]))
		elif method == 'idf':
			avg = 0
			for j in range(len(curRec[2])):
				curVector = curVector +[x* curRec[2][j][2] for x in curRec[2][j][0]]
				tags[i][int(curRec[2][j][1])] = 1
				avg = avg + curRec[2][j][2]
			vecMat[i][:] = curVector/float(avg)
		elif method == 'minFreq':
			minFreq = 100
			minFrqIndex = -100
			for j in range(len(curRec[2])):
				if curRec[2][j][2] < minFreq:
					tags[i][int(curRec[2][j][1])] = 1
					minFreq = curRec[2][j][2]
					minFreqIndex = j
			vecMat[i][:] = curRec[2][minFreqIndex][0]
		elif method == 'cutFreq':
			avg = 0.00001
			for j in range(len(curRec[2])):
				if curRec[2][j][2] > 5.3 and curRec[2][j][2] < 8.2:
					curVector = curVector +[x* curRec[2][j][2] for x in curRec[2][j][0]]
					tags[i][int(curRec[2][j][1])] = 1
					avg = avg + curRec[2][j][2]
			vecMat[i][:] = curVector/float(avg)
	images = np.array(images, dtype='uint32')			
	return (images, labels, vecMat, tags)

def multiLabelGetVectorsNUS(data, dim=300, nClasses=81, nTags=1000, method='mean'):
	vecMat = np.zeros((len(data), dim))
	labels = np.zeros((len(data), nClasses))
	images = np.zeros((len(data), 1))
	tags = []
	for i in range(len(data)):
		curRec = data[i]

		curVector = np.zeros((300, ))
		images[i] = curRec[0]
		labels[i] = curRec[1]
		if method == 'mean':
			for j in range(len(curRec[2])):
				curVector = curVector + curRec[2][j]
			vecMat[i][:] = curVector/float(len(curRec[2]))
			tags.append(curRec[3])
		elif method == 'idf':
			avg = 0
			for j in range(len(curRec[2])):
				curVector = curVector +[x* curRec[2][j][2] for x in curRec[2][j][0]]
				avg = avg + curRec[2][j][2]
			vecMat[i][:] = curVector/float(avg)
		elif method == 'minFreq':
			minFreq = 100
			minFrqIndex = -100
			for j in range(len(curRec[2])):
				if curRec[2][j][2] < minFreq:
					minFreq = curRec[2][j][2]
					minFreqIndex = j
			vecMat[i][:] = curRec[2][minFreqIndex][0]
		elif method == 'cutFreq':
			avg = 0.00001
			for j in range(len(curRec[2])):
				if curRec[2][j][2] > 5.3 and curRec[2][j][2] < 8.2:
					curVector = curVector +[x* curRec[2][j][2] for x in curRec[2][j][0]]
					avg = avg + curRec[2][j][2]
			vecMat[i][:] = curVector/float(avg)
	images = np.array(images, dtype='uint32')			
	return (images, labels, vecMat, tags)

def multiLabelGetVectorsDelete(data, dim=300, nClasses=81, nTags=1000, method='mean'):
	vecMat = np.zeros((len(data), dim))
	labels = np.zeros((len(data), nClasses))
	images = np.zeros((len(data), 1))
	tags = np.zeros((len(data), nTags))
	for i in range(len(data)):
		curRec = data[i]
		images[i] = curRec[0]
		labels[i] = curRec[1]
	images = np.array(images, dtype='uint32')			
	return (images, labels)

def getSvd(S):
	import numpy.linalg as la
	try:
		u, e, v = la.svd(S, full_matrices=True)
	except:
		u=0
		e=0
		v=0
	return u, e, v

def get_image(image_path): # Default is PIL format, which is RGB
    image = Image.open(image_path)
    (im_width, im_height) = image.size
    # You have to put it in height, width order while reshaping
    image = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8) 
    return image, im_width, im_height
    
def parse_csv(path, debug=False):
    output_list = list()
    with open(path) as csvfile:
        reader = csv.reader(csvfile)
        c = 0
        for row in reader:
            if c % 100 == 0 and debug:
                print(c)
            output_list.append(row)
            c=c+1
    return output_list

def write_to_json(output_file, dict_data):
    import json
    with open(output_file, 'w') as fp:
        json.dump(dict_data, fp)
        
def clean_image_name(im_name): 
    start_ind = im_name.rfind('/')
    end_ind = im_name.rfind('.')
    im_name_new = im_name[start_ind+1:end_ind]
    return im_name_new

def load_json(input_json):
    with open(input_json) as json_file:
        data = json.load(json_file)
    return data

def convert_databee_format(labels):
    im_height = 1024
    im_width = 1024
    outputs = []
    for i in range(len(labels)):
        l = load_json(labels[i])
        r = [labels[i][-81:-4], len(l)]
        for j in range(len(l)):
            cur_l = l[j]['C']
            if cur_l != "SKIP":
                cur_b = [l[j]['R']['X1']/im_width, l[j]['R']['Y1']/im_height, (l[j]['R']['X2'] - l[j]['R']['X1'])/im_width, (l[j]['R']['Y2'] - l[j]['R']['Y1'])/im_height]
                r = r + [cur_l, 1.0]+cur_b
            else:
                r[-1]=r[-1]-1
        outputs.append(r)
    return outputs

def count_n_boxes(data):
    n = 0
    for i in range(len(data)):
        n+=int(data[i][1])
    return n 

def row_to_boxes(row, width, height):
    boxes = []
    for i in range(int(row[1])):
        ind = 2+6*i
        x=int(float(row[ind+2])*width)
        y=int(float(row[ind+3])*height)
        w=int(float(row[ind+4])*width)
        h=int(float(row[ind+5])*height)
        conf = float(row[ind+1])
        if conf > 0.5:
            boxes.append([conf, (x, y, w, h)])
    return boxes

def clean_label_name(label):
    try:
        label = str(label)
        label = ''.join(e for e in label if e.isalnum())
        label = label.lower()
    except:
        pdb.set_trace()
    return label

def get_cat_id(label):
    label = label.encode('ascii','ignore').decode('utf-8')
    label = clean_label_name(label)
    mapping = {1: 'microwave', 
              2: 'oven', 
              3: 'stove', 
              4: 'clothwasher', 
              5: 'refrigerator',
              6: 'dishwasher'}
    for k in mapping:
        if mapping[k] == label:
            return k
    
def make_mpkitchen_dataset(file_name, width=1024, height=1024):
    from detectron2.structures import BoxMode
    dataset_dicts = []
    anns = parse_csv(file_name)
    for i in range(len(anns)):
        record={}
        record['filename']=anns[i][0]
        record["image_id"] = i
        record["height"] = width
        record["width"] = height
        objs = []
        for j in range(int(anns[i][1])):
            ind = 2+6*j
            x=int(float(anns[i][ind+2])*width)
            y=int(float(anns[i][ind+3])*height)
            w=int(float(anns[i][ind+4])*width)
            h=int(float(anns[i][ind+5])*height)
            label = get_cat_id(anns[i][ind])
            obj = {
                "bbox": [x, y, w, h],
                "bbox_mode": BoxMode.XYWH_ABS,
                "category_id": label,
                "iscrowd": 0
            }
            if label != None:
            	objs.append(obj)
        record["annotations"] = objs
        dataset_dicts.append(record)
    return dataset_dicts
    
def write_to_csv(output_csv, rows, delimiter=","):
    with open(output_csv, 'w') as csvfile:
        writer = csv.writer(csvfile, delimiter=delimiter)
        writer.writerows(rows)
        